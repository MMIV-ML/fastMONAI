{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2585a7f0-c4c3-40cc-b87d-9c8c056d0b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp dataset_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab88ecb-d5fb-4ceb-a5a9-608dcd20e0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027f016a-a80c-4842-b9dc-0bddb358a00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "from fastMONAI.vision_core import *\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74812108-f3eb-4a8d-9f2d-b93132619008",
   "metadata": {},
   "source": [
    "# Dataset information\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3593203e-e5e1-4564-94d4-8e31b7048cf9",
   "metadata": {},
   "outputs": [],
   "source": "#| export\nclass MedDataset:\n    \"\"\"A class to extract and present information about the dataset.\"\"\"\n\n    def __init__(self, path=None, postfix: str = '', img_list: list = None,\n                 reorder: bool = False, dtype: (MedImage, MedMask) = MedImage,\n                 max_workers: int = 1):\n        \"\"\"Constructs MedDataset object.\n\n        Args:\n            path (str, optional): Path to the image folder.\n            postfix (str, optional): Specify the file type if there are different files in the folder.\n            img_list (List[str], optional): Alternatively, pass in a list with image paths.\n            reorder (bool, optional): Whether to reorder the data to be closest to canonical (RAS+) orientation.\n            dtype (Union[MedImage, MedMask], optional): Load data as datatype. Default is MedImage.\n            max_workers (int, optional): The number of worker threads. Default is 1.\n        \"\"\"\n                     \n        self.path = path\n        self.postfix = postfix\n        self.img_list = img_list\n        self.reorder = reorder\n        self.dtype = dtype\n        self.max_workers = max_workers\n        self.df = self._create_data_frame()\n\n    def _create_data_frame(self):\n        \"\"\"Private method that returns a dataframe with information about the dataset.\"\"\"\n\n        if self.path:\n            self.img_list = glob.glob(f'{self.path}/*{self.postfix}*')\n            if not self.img_list: print('Could not find images. Check the image path')\n\n        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n            data_info_dict = list(executor.map(self._get_data_info, self.img_list))\n\n        df = pd.DataFrame(data_info_dict)\n        \n        if df.orientation.nunique() > 1:\n            print('The volumes in this dataset have different orientations. '\n                  'Recommended to pass in the argument reorder=True when creating a MedDataset object for this dataset')\n\n        return df\n\n    def summary(self):\n        \"\"\"Summary DataFrame of the dataset with example path for similar data.\"\"\"\n        \n        columns = ['dim_0', 'dim_1', 'dim_2', 'voxel_0', 'voxel_1', 'voxel_2', 'orientation']\n        \n        return self.df.groupby(columns, as_index=False).agg(\n            example_path=('path', 'min'), total=('path', 'size')\n        ).sort_values('total', ascending=False)\n\n    def suggestion(self):\n        \"\"\"Voxel value that appears most often in dim_0, dim_1 and dim_2, and whether the data should be reoriented.\"\"\"\n        \n        resample = [float(self.df.voxel_0.mode()[0]), float(self.df.voxel_1.mode()[0]), float(self.df.voxel_2.mode()[0])]\n        return resample, self.reorder\n\n    def _get_data_info(self, fn: str):\n        \"\"\"Private method to collect information about an image file.\"\"\"\n        _, o, _ = med_img_reader(fn, reorder=self.reorder, only_tensor=False, dtype=self.dtype)\n\n        info_dict = {'path': fn, 'dim_0': o.shape[1], 'dim_1': o.shape[2], 'dim_2': o.shape[3],\n                     'voxel_0': round(o.spacing[0], 4), 'voxel_1': round(o.spacing[1], 4), 'voxel_2': round(o.spacing[2], 4),\n                     'orientation': f'{\"\".join(o.orientation)}+'}\n\n        if self.dtype is MedMask:\n            mask_labels_dict = o.count_labels()\n            mask_labels_dict = {f'voxel_count_{int(key)}': val for key, val in mask_labels_dict.items()}\n            info_dict.update(mask_labels_dict)\n\n        return info_dict\n\n    def get_largest_img_size(self, resample: list = None) -> list:\n        \"\"\"Get the largest image size in the dataset.\"\"\"\n        \n        dims = None\n\n        if resample is not None:\n            org_voxels = self.df[[\"voxel_0\", \"voxel_1\", 'voxel_2']].values\n            org_dims = self.df[[\"dim_0\", \"dim_1\", 'dim_2']].values\n\n            ratio = org_voxels/resample\n            new_dims = (org_dims * ratio).T\n            dims = [float(new_dims[0].max().round()), float(new_dims[1].max().round()), float(new_dims[2].max().round())]\n\n        else:\n            dims = [float(self.df.dim_0.max()), float(self.df.dim_1.max()), float(self.df.dim_2.max())]\n\n        return dims"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b81f6e8-abd7-4bf6-be4c-4118986c308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def get_class_weights(labels: (np.array, list), class_weight: str = 'balanced') -> torch.Tensor: \n",
    "    \"\"\"Calculates and returns the class weights.\n",
    "\n",
    "    Args:\n",
    "        labels: An array or list of class labels for each instance in the dataset.\n",
    "        class_weight: Defaults to 'balanced'.\n",
    "\n",
    "    Returns:\n",
    "        A tensor of class weights.\n",
    "    \"\"\"\n",
    "    \n",
    "    class_weights =  compute_class_weight(class_weight=class_weight, classes=np.unique(labels), y=labels)\n",
    "    \n",
    "    return torch.Tensor(class_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
