{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce07e17d-82d7-4d42-b6b7-6ee80a55341b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp vision_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eee6b3-75c3-4468-8645-8f6a42a76bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "from fastMONAI.vision_core import *\n",
    "from fastMONAI.vision_data import pred_to_binary_mask, batch_pred_to_multiclass_mask\n",
    "from monai.losses import TverskyLoss, FocalLoss\n",
    "from torch.nn.modules.loss import _Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5931e820-48c8-46d9-a30f-0172dc708f26",
   "metadata": {},
   "source": [
    "# Custom loss functions\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b589b6c4-b620-428c-abcf-bcf4e7aa3a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CustomLoss:\n",
    "    '''Wrapper to get show_results to work.'''\n",
    "\n",
    "    def __init__(self, loss_func):\n",
    "        self.loss_func = loss_func\n",
    "\n",
    "    def __call__(self, pred, targ):\n",
    "        if isinstance(pred, MedBase): pred, targ = torch.Tensor(pred.cpu()), torch.Tensor(targ.cpu().float())\n",
    "        return self.loss_func(pred, targ)\n",
    "\n",
    "    def activation(self, x):\n",
    "        return x\n",
    "    \n",
    "    def decodes(self, x):\n",
    "        '''Converts model output to target format.\n",
    "\n",
    "        Args:\n",
    "            x: Activations for each class [B, C, W, H, D]\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Predicted mask.\n",
    "        '''\n",
    "\n",
    "        n_classes = x.shape[1]\n",
    "        if n_classes == 1: x = pred_to_binary_mask(x)\n",
    "        else: x,_ = batch_pred_to_multiclass_mask(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00d0530-ad8b-46fd-a38a-09fba5dd6f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TverskyFocalLoss(_Loss):\n",
    "    \"\"\"\n",
    "    Compute both Dice loss and Focal Loss, and return the weighted sum of these two losses.\n",
    "    The details of Dice loss is shown in ``monai.losses.DiceLoss``.\n",
    "    The details of Focal Loss is shown in ``monai.losses.FocalLoss``.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        include_background: bool = True,\n",
    "        to_onehot_y: bool = False,\n",
    "        sigmoid: bool = False,\n",
    "        softmax: bool = False,\n",
    "        reduction: str = \"mean\",\n",
    "        gamma: float = 2,\n",
    "        #focal_weight: (float, int, torch.Tensor) = None,\n",
    "        #lambda_dice: float = 1.0,\n",
    "        #lambda_focal: float = 1.0,\n",
    "        alpha = 0.5, \n",
    "        beta = 0.99\n",
    "    ) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "        self.tversky = TverskyLoss(to_onehot_y=to_onehot_y, include_background=include_background, sigmoid=sigmoid, softmax=softmax, alpha=alpha, beta=beta)\n",
    "        #self.focal = FocalLoss(to_onehot_y=to_onehot_y, include_background=include_background, gamma=gamma, weight=focal_weight, reduction=reduction)\n",
    "        \n",
    "        #if lambda_dice < 0.0: raise ValueError(\"lambda_dice should be no less than 0.0.\")\n",
    "        #if lambda_focal < 0.0: raise ValueError(\"lambda_focal should be no less than 0.0.\")\n",
    "        #self.lambda_dice = lambda_dice\n",
    "        #self.lambda_focal = lambda_focal\n",
    "        self.to_onehot_y = to_onehot_y\n",
    "        self.gamma = gamma\n",
    "        self.include_background = include_background\n",
    "\n",
    "    def forward(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input: the shape should be BNH[WD]. The input should be the original logits\n",
    "                due to the restriction of ``monai.losses.FocalLoss``.\n",
    "            target: the shape should be BNH[WD] or B1H[WD].\n",
    "        Raises:\n",
    "            ValueError: When number of dimensions for input and target are different.\n",
    "            ValueError: When number of channels for target is neither 1 nor the same as input.\n",
    "        \"\"\"\n",
    "        if len(input.shape) != len(target.shape):\n",
    "            raise ValueError(\"the number of dimensions for input and target should be the same.\")\n",
    "\n",
    "        n_pred_ch = input.shape[1]\n",
    "\n",
    "        tversky_loss = self.tversky(input, target)\n",
    "        #focal_loss = self.focal(input, target)\n",
    "        total_loss: torch.Tensor = 1 - ((1 - tversky_loss)**self.gamma) #tversky_loss\n",
    "        #print(total_loss,total_loss.shape)\n",
    "        #tversky_loss +  focal_loss\n",
    "        return total_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
