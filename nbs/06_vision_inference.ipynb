{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daf47f4-572e-4473-91e6-51d141d928ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp vision_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28504fd-0e10-4a0e-8ac5-3be955aa3622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from copy import copy\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.ndimage import label\n",
    "from skimage.morphology import remove_small_objects\n",
    "from SimpleITK import DICOMOrient, GetArrayFromImage\n",
    "from torchio import Resize, Image\n",
    "from fastMONAI.vision_core import *\n",
    "from fastMONAI.vision_augmentation import do_pad_or_crop\n",
    "from fastMONAI.utils import load_variables\n",
    "from imagedata.series import Series\n",
    "from fastai.learner import load_learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984e4b90-979b-4d04-bc42-b667400163ea",
   "metadata": {},
   "source": [
    "# Vision inference\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d8ecaf-d80c-463b-84f8-197e8966b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _update_uid(attribute, series_obj, val='1234', slice_idx=None):\n",
    "    \"\"\"Updates a DICOM UID by replacing its last 4 characters with the provided value.\"\"\"\n",
    "    \n",
    "    uid = series_obj.getDicomAttribute(attribute, slice=slice_idx)[:-4] + val\n",
    "    series_obj.setDicomAttribute(attribute, uid, slice=slice_idx)\n",
    "    return series_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd80eb1-915e-4ea1-91e0-b68738743e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save_series_pred(series_obj, save_dir, val='1234'):\n",
    "    \"\"\"Saves series prediction with updated DICOM UIDs.\"\"\"\n",
    "    \n",
    "    series_obj.seriesInstanceUID = series_obj.seriesInstanceUID[:-4] + val\n",
    "    \n",
    "    for slice_idx in range(series_obj.slices):\n",
    "        series_obj = _update_uid('SOPInstanceUID', series_obj, val, slice_idx)\n",
    "        series_obj = _update_uid('SeriesInstanceUID', series_obj, val, slice_idx)\n",
    "        \n",
    "    series_obj.write(save_dir, opts={'keep_uid': True}, formats=['dicom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a2771e-25aa-4669-bda2-abcbe29d0504",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _to_original_orientation(input_img, org_orientation):\n",
    "    \"\"\"Reorients the image to its original orientation.\"\"\"\n",
    "    \n",
    "    orientation_itk = DICOMOrient(input_img, org_orientation)\n",
    "    reoriented_array =  GetArrayFromImage(orientation_itk).transpose()\n",
    "    \n",
    "    return reoriented_array[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a1169f-7385-4c48-9a24-51994c80732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _do_resize(o, target_shape, image_interpolation='linear', \n",
    "               label_interpolation='nearest'):\n",
    "    \"\"\"Resample images so the output shape matches the given target shape.\"\"\"\n",
    "\n",
    "    resize = Resize(\n",
    "        target_shape, \n",
    "        image_interpolation=image_interpolation, \n",
    "        label_interpolation=label_interpolation\n",
    "    )\n",
    "    \n",
    "    return resize(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee89fef9-1e9d-4d70-8c93-e44e2d600c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_system_resources(models_path, learner_fn, variables_fn):\n",
    "    \"\"\"Load necessary resources like learner and variables.\"\"\"\n",
    "\n",
    "    learn = load_learner(models_path / learner_fn, cpu=True) \n",
    "    vars_fn = models_path / variables_fn\n",
    "    _, reorder, resample = load_variables(pkl_fn=vars_fn)\n",
    "\n",
    "    return learn, reorder, resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba94a55-2cd1-4fae-b8b4-e82051be0cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def inference(learn_inf, reorder, resample, fn: (str, Path) = '',\n",
    "              save_path: (str, Path) = None, org_img=None, input_img=None,\n",
    "              org_size=None): \n",
    "    \"\"\"Predict on new data using exported model.\"\"\"         \n",
    "    \n",
    "    if None in [org_img, input_img, org_size]: \n",
    "        org_img, input_img, org_size = med_img_reader(fn, reorder, resample, \n",
    "                                                      only_tensor=False)\n",
    "    else: \n",
    "        org_img, input_img = copy(org_img), copy(input_img)\n",
    "    \n",
    "    pred, *_ = learn_inf.predict(input_img.data)\n",
    "    \n",
    "    pred_mask = do_pad_or_crop(pred.float(), input_img.shape[1:], padding_mode=0, \n",
    "                               mask_name=None)\n",
    "    input_img.set_data(pred_mask)\n",
    "    \n",
    "    input_img = _do_resize(input_img, org_size, image_interpolation='nearest')\n",
    "    \n",
    "    reoriented_array = _to_original_orientation(input_img.as_sitk(), \n",
    "                                                ('').join(org_img.orientation))\n",
    "    \n",
    "    org_img.set_data(reoriented_array)\n",
    "\n",
    "    if save_path:\n",
    "        save_fn = Path(save_path)/('pred_' + Path(fn).parts[-1])\n",
    "        org_img.save(save_fn)\n",
    "        return save_fn\n",
    "    \n",
    "    return org_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1730df1e-e6d7-4fa7-b40e-83f4dda26dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def compute_binary_tumor_volume(mask_data: Image):\n",
    "    \"\"\"Compute the volume of the tumor in milliliters (ml).\"\"\"\n",
    "    \n",
    "    dx, dy, dz = mask_data.spacing\n",
    "    voxel_volume_ml = dx * dy * dz / 1000  \n",
    "    return np.sum(mask_data) * voxel_volume_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae73163b-42e5-4363-b067-d52fb4c011c2",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64a3407-4b97-4b1c-933c-d4a316dbff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def refine_binary_pred_mask(pred_mask, \n",
    "                            remove_size: (int, float) = None,\n",
    "                            percentage: float = 0.2,\n",
    "                            verbose: bool = False) -> torch.Tensor:\n",
    "    \"\"\"Removes small objects from the predicted binary mask.\n",
    "\n",
    "    Args:\n",
    "        pred_mask: The predicted mask from which small objects are to be removed.\n",
    "        remove_size: The size under which objects are considered 'small'.\n",
    "        percentage: The percentage of the remove_size to be used as threshold. \n",
    "            Defaults to 0.2.\n",
    "        verbose: If True, print the number of components. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        The processed mask with small objects removed.\n",
    "    \"\"\"\n",
    "                                \n",
    "    labeled_mask, n_components = label(pred_mask)\n",
    "\n",
    "    if verbose:\n",
    "        print(n_components)\n",
    "\n",
    "    if remove_size is None:\n",
    "        sizes = np.bincount(labeled_mask.ravel())\n",
    "        max_label = sizes[1:].argmax() + 1\n",
    "        remove_size = sizes[max_label]\n",
    "\n",
    "    small_objects_threshold = remove_size * percentage\n",
    "    processed_mask = remove_small_objects(\n",
    "        labeled_mask, min_size=small_objects_threshold)\n",
    "\n",
    "    return torch.Tensor(processed_mask > 0).float()                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d847704-be92-4761-988d-6a027c238e32",
   "metadata": {},
   "source": [
    "## Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b11267-d760-44b0-bd1b-06fd392ce911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def gradio_image_classifier(file_obj, learn, reorder, resample):\n",
    "    \"\"\"Predict on images using exported learner and return the result as a dictionary.\"\"\"\n",
    "    \n",
    "    img_path = Path(file_obj.name)\n",
    "    img = med_img_reader(img_path, reorder=reorder, resample=resample)\n",
    "    \n",
    "    _, _, predictions = learn.predict(img)\n",
    "    prediction_dict = {index: value.item() for index, value in enumerate(predictions)}\n",
    "\n",
    "    return prediction_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
