{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e339eff2-b4a5-46c8-9622-f5d123f5338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac941446-cf7e-4f5c-ace0-a36fb078022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "import pickle\n",
    "import torch\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ea67a2-281a-4c96-9869-6e1a1050f44b",
   "metadata": {},
   "source": [
    "# Utils\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f954a64-c9df-4ee8-b70a-fce7f857eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def store_variables(pkl_fn:(str, Path),\n",
    "                    size:list,\n",
    "                    reorder:bool,\n",
    "                    resample:(int,list),\n",
    "                   ) -> None:\n",
    "    \"\"\"Save variable values in a pickle file.\"\"\"\n",
    "    \n",
    "    var_vals = [size, reorder, resample]\n",
    "    \n",
    "    with open(pkl_fn, 'wb') as f:\n",
    "        pickle.dump(var_vals, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2db5512-171c-4dfd-a26e-561b773a6069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_variables(pkl_fn: (str, Path)) -> Any:\n",
    "    \"\"\"\n",
    "    Loads stored variable values from a pickle file.\n",
    "\n",
    "    Args:\n",
    "        pkl_fn: File path of the pickle file to be loaded.\n",
    "\n",
    "    Returns:\n",
    "        The deserialized value of the pickled data.\n",
    "    \"\"\"\n",
    "    with open(pkl_fn, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e1513a-25d6-497a-bec3-6adc008452d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def print_colab_gpu_info(): \n",
    "    \"\"\"Check if we have a GPU attached to the runtime.\"\"\"\n",
    "    \n",
    "    colab_gpu_msg =(f\"{'#'*80}\\n\"\n",
    "                    \"Remember to attach a GPU to your Colab Runtime:\"\n",
    "                    \"\\n1. From the **Runtime** menu select **Change Runtime Type**\"\n",
    "                    \"\\n2. Choose **GPU** from the drop-down menu\"\n",
    "                    \"\\n3. Click **'SAVE'**\\n\"\n",
    "                    f\"{'#'*80}\")\n",
    "    \n",
    "    if torch.cuda.is_available(): print('GPU attached.')\n",
    "    else: print(colab_gpu_msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastmonai",
   "language": "python",
   "name": "fastmonai"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
