{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88489e47-cff3-4838-abff-850a74cfd443",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp external_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942e1644-0dac-4701-8a1e-5693f80f3ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from numpy import load \n",
    "import pandas as pd\n",
    "from monai.apps import download_url, download_and_extract\n",
    "from torchio.datasets.ixi import IXITiny\n",
    "from torchio import ScalarImage\n",
    "import multiprocessing as mp\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f58a916-1e2d-4a59-a1a2-83e7fe8eb0ee",
   "metadata": {},
   "source": [
    "# External data\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5600a3-9d70-4714-8cc2-8f4682a7e5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MURLs():\n",
    "    \"\"\"A class with external medical dataset URLs.\"\"\"\n",
    "\n",
    "    IXI_DATA = 'http://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI-T1.tar'\n",
    "    IXI_DEMOGRAPHIC_INFORMATION = 'http://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI.xls'\n",
    "    CHENGWEN_CHU_SPINE_DATA = 'https://drive.google.com/uc?id=1rbm9-KKAexpNm2mC9FsSbfnS8VJaF3Kn&confirm=t'\n",
    "    EXAMPLE_SPINE_DATA = 'https://drive.google.com/uc?id=1Ms3Q6MYQrQUA_PKZbJ2t2NeYFQ5jloMh'\n",
    "    MEDMNIST_DICT = {'OrganMNIST3D': 'https://zenodo.org/record/6496656/files/organmnist3d.npz?download=1',\t\n",
    "                     'NoduleMNIST3D': 'https://zenodo.org/record/6496656/files/nodulemnist3d.npz?download=1',\n",
    "                     'AdrenalMNIST3D': 'https://zenodo.org/record/6496656/files/adrenalmnist3d.npz?download=1',\t\n",
    "                     'FractureMNIST3D': 'https://zenodo.org/record/6496656/files/fracturemnist3d.npz?download=1',\n",
    "                     'VesselMNIST3D': 'https://zenodo.org/record/6496656/files/vesselmnist3d.npz?download=1', \n",
    "                     'SynapseMNIST3D': 'https://zenodo.org/record/6496656/files/synapsemnist3d.npz?download=1'}\n",
    "    EXAMPLE_EC_DATA = 'https://drive.google.com/uc?id=1cjOBhkdRsoX3unxHiL377R5j8ottN4An'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4c061a-d7f5-4ba0-9e7b-ee0c6ec480b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _process_ixi_xls(xls_path: (str, Path), img_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Private method to process the demographic information for the IXI dataset.\n",
    "\n",
    "    Args:\n",
    "        xls_path: File path to the xls file with the demographic information.\n",
    "        img_path: Folder path to the images.\n",
    "\n",
    "    Returns:\n",
    "        A processed dataframe with image path and demographic information.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If xls_path or img_path do not exist.\n",
    "    \"\"\"\n",
    "\n",
    "    print('Preprocessing ' + str(xls_path))\n",
    "\n",
    "    df = pd.read_excel(xls_path)\n",
    "\n",
    "    duplicate_subject_ids = df[df.duplicated(['IXI_ID'], keep=False)].IXI_ID.unique()\n",
    "\n",
    "    for subject_id in duplicate_subject_ids:\n",
    "        age = df.loc[df.IXI_ID == subject_id].AGE.nunique()\n",
    "        if age != 1: df = df.loc[df.IXI_ID != subject_id]  # Remove duplicates with two different age values\n",
    "\n",
    "    df = df.drop_duplicates(subset='IXI_ID', keep='first').reset_index(drop=True)\n",
    "\n",
    "    df['subject_id'] = ['IXI' + str(subject_id).zfill(3) for subject_id in df.IXI_ID.values]\n",
    "    df = df.rename(columns={'SEX_ID (1=m, 2=f)': 'gender'})\n",
    "    df['age_at_scan'] = df.AGE.round(2)\n",
    "    df = df.replace({'gender': {1: 'M', 2: 'F'}})\n",
    "\n",
    "    img_list = list(img_path.glob('*.nii.gz'))\n",
    "    for path in img_list:\n",
    "        subject_id = path.parts[-1].split('-')[0]\n",
    "        df.loc[df.subject_id == subject_id, 't1_path'] = str(path)\n",
    "\n",
    "    df = df.dropna()\n",
    "    df = df[['t1_path', 'subject_id', 'gender', 'age_at_scan']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b381c8e2-6e7b-4d32-bcf7-76a1245ed893",
   "metadata": {},
   "source": [
    "## IXI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6714a68f-1378-46b3-aeff-ef940213ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def download_ixi_data(path: (str, Path) = '../data') -> Path:\n",
    "    \"\"\"Download T1 scans and demographic information from the IXI dataset.\n",
    "    \n",
    "    Args:\n",
    "        path: Path to the directory where the data will be stored. Defaults to '../data'.\n",
    "\n",
    "    Returns:\n",
    "        The path to the stored CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    path = Path(path) / 'IXI'\n",
    "    img_path = path / 'T1_images'\n",
    "\n",
    "    # Check whether image data already present in img_path:\n",
    "    is_extracted = False\n",
    "    try:\n",
    "        if len(list(img_path.iterdir())) >= 581:  # 581 imgs in the IXI dataset\n",
    "            is_extracted = True\n",
    "            print(f\"Images already downloaded and extracted to {img_path}\")\n",
    "    except:\n",
    "        is_extracted = False\n",
    "\n",
    "    if not is_extracted:\n",
    "        download_and_extract(url=MURLs.IXI_DATA, filepath=path / 'IXI-T1.tar', output_dir=img_path)\n",
    "        (path / 'IXI-T1.tar').unlink()\n",
    "\n",
    "    download_url(url=MURLs.IXI_DEMOGRAPHIC_INFORMATION, filepath=path / 'IXI.xls')\n",
    "\n",
    "    processed_df = _process_ixi_xls(xls_path=path / 'IXI.xls', img_path=img_path)\n",
    "    processed_df.to_csv(path / 'dataset.csv', index=False)\n",
    "\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad67127-c0c7-40e7-972d-120c09ebb527",
   "metadata": {},
   "source": [
    "## IXITiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7753da8a-93e8-4bf3-8f78-bb158b4280d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def download_ixi_tiny(path: (str, Path) = '../data') -> Path:\n",
    "    \"\"\"Download the tiny version of the IXI dataset provided by TorchIO.\n",
    "\n",
    "    Args:\n",
    "        path: The directory where the data will be \n",
    "            stored. If not provided, defaults to '../data'.\n",
    "\n",
    "    Returns:\n",
    "        The path to the directory where the data is stored.\n",
    "    \"\"\"\n",
    "    \n",
    "    path = Path(path) / 'IXITiny'\n",
    "    \n",
    "    IXITiny(root=str(path), download=True)\n",
    "    download_url(url=MURLs.IXI_DEMOGRAPHIC_INFORMATION, filepath=path/'IXI.xls')\n",
    "    \n",
    "    processed_df = _process_ixi_xls(xls_path=path/'IXI.xls', img_path=path/'image')\n",
    "    processed_df['labels'] = processed_df['t1_path'].str.replace('image','label')\n",
    "    \n",
    "    processed_df.to_csv(path/'dataset.csv', index=False)\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17de9ba6-00b5-408e-8dee-abafc62926ef",
   "metadata": {},
   "source": [
    "## Lower spine data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b466174a-4b49-4a8f-92c6-1e5e3ca9fc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _create_spine_df(dir: Path) -> pd.DataFrame:\n",
    "    \"\"\"Create a pandas DataFrame containing information about spinal images.\n",
    "\n",
    "    Args:\n",
    "        dir: Directory path where data (image and segmentation \n",
    "            mask files) are stored.\n",
    "\n",
    "    Returns:\n",
    "         A DataFrame containing the paths to the image files and their \n",
    "            corresponding mask files, the subject IDs, and a flag indicating that \n",
    "            these are test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    img_list = glob(str(dir / 'img/*.nii.gz'))\n",
    "    mask_list = [str(fn).replace('img', 'seg') for fn in img_list]\n",
    "    subject_id_list = [fn.split('_')[-1].split('.')[0] for fn in mask_list]\n",
    "    \n",
    "    test_data = {\n",
    "        't2_img_path': img_list,\n",
    "        't2_mask_path': mask_list,\n",
    "        'subject_id': subject_id_list,\n",
    "        'is_test': True,\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26256dca-d9df-43f6-b8eb-f36ce2a445dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export  \n",
    "def download_spine_test_data(path: (str, Path) = '../data') -> pd.DataFrame:\n",
    "    \"\"\"Downloads T2w scans from the study 'Fully Automatic Localization and \n",
    "    Segmentation of 3D Vertebral Bodies from CT/MR Images via a Learning-Based \n",
    "    Method' by Chu et. al. \n",
    "\n",
    "    Args:\n",
    "        path: Directory where the downloaded data \n",
    "            will be stored and extracted. Defaults to '../data'.\n",
    "\n",
    "    Returns:\n",
    "        Processed dataframe containing image paths, label paths, and subject IDs.\n",
    "    \"\"\"\n",
    "    \n",
    "    study = 'chengwen_chu_2015'\n",
    "    \n",
    "    download_and_extract(\n",
    "        url=MURLs.CHENGWEN_CHU_SPINE_DATA, \n",
    "        filepath=f'{study}.zip', \n",
    "        output_dir=path\n",
    "    )\n",
    "    Path(f'{study}.zip').unlink()\n",
    "    \n",
    "    return _create_spine_df(Path(path) / study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b77ec9-a93a-42cc-b707-4e1e75063533",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def download_example_spine_data(path: (str, Path) = '../data') -> Path:\n",
    "    \"\"\"Downloads example T2w scan and corresponding predicted mask.\n",
    "    \n",
    "    Args:\n",
    "        path: Directory where the downloaded data \n",
    "            will be stored and extracted. Defaults to '../data'.\n",
    "\n",
    "    Returns:\n",
    "        Path to the directory where the example data has been extracted.\n",
    "    \"\"\"\n",
    "    \n",
    "    study = 'example_data'\n",
    "    \n",
    "    download_and_extract(\n",
    "        url=MURLs.EXAMPLE_SPINE_DATA, \n",
    "        filepath='example_data.zip', \n",
    "        output_dir=path\n",
    "    )\n",
    "    Path('example_data.zip').unlink()\n",
    "    \n",
    "    return Path(path) / study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228c0417-392c-4897-949c-d2cb572cd855",
   "metadata": {},
   "source": [
    "## MedMNIST3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f60f76-5e5d-4a40-b49a-617ec2d35731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def _process_medmnist_img(path, idx_arr):\n",
    "    \"\"\"Save tensor as NIfTI.\"\"\"\n",
    "    \n",
    "    idx, arr = idx_arr\n",
    "    img = ScalarImage(tensor=arr[None, :])\n",
    "    fn = path/f'{idx}_nodule.nii.gz'\n",
    "    img.save(fn)\n",
    "    return str(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0199679-707b-445d-8467-3d342246322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def _df_sort_and_add_columns(df, label_list, is_val):\n",
    "    \"\"\"Sort the dataframe based on img_idx and add labels and if it is validation data column.\"\"\"\n",
    "    \n",
    "    df = df.sort_values(by='img_idx').reset_index(drop=True)\n",
    "    df['labels'], df['is_val'] = label_list, is_val     \n",
    "    #df = df.replace({\"labels\": {0:'b', 1:'m'}})\n",
    "    df = df.drop('img_idx', axis=1)\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82157b8-ab69-4a38-9323-af4b58c6b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def _create_nodule_df(pool, output_dir, imgs, labels, is_val=False): \n",
    "    \"\"\"Create dataframe for MedMNIST data.\"\"\"\n",
    "    \n",
    "    img_path_list = pool.map(partial(_process_medmnist_img, output_dir), enumerate(imgs))\n",
    "    img_idx = [float(Path(fn).parts[-1].split('_')[0]) for fn in img_path_list]\n",
    "    \n",
    "    df = pd.DataFrame(list(zip(img_path_list, img_idx)), columns=['img_path','img_idx'])        \n",
    "    return  _df_sort_and_add_columns(df, labels, is_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b456f0-8e14-42c6-a1cd-a332312145ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def download_medmnist3d_dataset(study: str, path: (str, Path) = '../data',\n",
    "                                max_workers: int = 1):\n",
    "    \"\"\"Downloads and processes a particular MedMNIST3D dataset.\n",
    "\n",
    "    Args:\n",
    "        study: MedMNIST dataset ('OrganMNIST3D', 'NoduleMNIST3D', \n",
    "               'AdrenalMNIST3D', 'FractureMNIST3D', 'VesselMNIST3D', 'SynapseMNIST3D')\n",
    "        path: Directory to store and extract downloaded data. Defaults to '../data'.\n",
    "        max_workers: Maximum number of worker processes for data processing. \n",
    "                     Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        Two pandas DataFrames. The first DataFrame combines training and validation \n",
    "        data, and the second DataFrame contains the testing data.\n",
    "    \"\"\"\n",
    "    path = Path(path) / study\n",
    "    dataset_file_path = path / f'{study}.npz'\n",
    "\n",
    "    try:\n",
    "        #todo: check if dataset is downloaded\n",
    "        download_url(url=MURLs.MEDMNIST_DICT[study], filepath=dataset_file_path)\n",
    "    except:\n",
    "        raise ValueError(f\"Dataset '{study}' does not exist.\")\n",
    "\n",
    "    data = load(dataset_file_path)\n",
    "    keys = ['train_images', 'val_images', 'test_images']\n",
    "\n",
    "    for key in keys:\n",
    "        (path / key).mkdir(exist_ok=True)\n",
    "\n",
    "    train_imgs = data[keys[0]]\n",
    "    val_imgs = data[keys[1]]\n",
    "    test_imgs = data[keys[2]]\n",
    "\n",
    "    with mp.Pool(processes=max_workers) as pool:\n",
    "        train_df = _create_nodule_df(pool, path / keys[0], train_imgs, \n",
    "                                     data['train_labels'])\n",
    "        val_df = _create_nodule_df(pool, path / keys[1], val_imgs, \n",
    "                                   data['val_labels'], is_val=True)\n",
    "        test_df = _create_nodule_df(pool, path / keys[2], test_imgs, \n",
    "                                    data['test_labels'])\n",
    "\n",
    "    train_val_df = pd.concat([train_df, val_df], ignore_index=True)\n",
    "\n",
    "    dataset_file_path.unlink()\n",
    "\n",
    "    return train_val_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7e2a84-23f5-4779-bea4-facd9124fb83",
   "metadata": {},
   "source": [
    "## Endometrical cancer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da78ddb3-e9e6-416b-a940-39cbac6a0344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def download_example_endometrial_cancer_data(path: (str, Path) = '../data') -> Path:\n",
    "    study = 'ec'\n",
    "    \n",
    "    download_and_extract(\n",
    "        url=MURLs.EXAMPLE_EC_DATA, \n",
    "        filepath='ec.zip', \n",
    "        output_dir=path\n",
    "    )\n",
    "    Path('ec.zip').unlink()\n",
    "    \n",
    "    return Path(path) / study"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
