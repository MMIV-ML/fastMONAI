{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88489e47-cff3-4838-abff-850a74cfd443",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp external_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e473e4-69ca-4fe9-ba7a-458f2f500eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942e1644-0dac-4701-8a1e-5693f80f3ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from monai.apps import download_url, download_and_extract\n",
    "from torchio.datasets.ixi import IXITiny\n",
    "from torchio import ScalarImage\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "from numpy import load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f58a916-1e2d-4a59-a1a2-83e7fe8eb0ee",
   "metadata": {},
   "source": [
    "# External data\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5600a3-9d70-4714-8cc2-8f4682a7e5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MURLs():\n",
    "    '''A class with external medical dataset URLs.'''\n",
    "\n",
    "    IXI_DATA = 'http://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI-T1.tar'\n",
    "    IXI_DEMOGRAPHIC_INFORMATION = 'http://biomedic.doc.ic.ac.uk/brain-development/downloads/IXI/IXI.xls'\n",
    "    CHENGWEN_CHU_SPINE_DATA = 'https://drive.google.com/uc?id=1rbm9-KKAexpNm2mC9FsSbfnS8VJaF3Kn&confirm=t'\n",
    "    EXAMPLE_SPINE_DATA = 'https://drive.google.com/uc?id=1Ms3Q6MYQrQUA_PKZbJ2t2NeYFQ5jloMh'\n",
    "    NODULE_MNIST_DATA = 'https://zenodo.org/record/6496656/files/nodulemnist3d.npz?download=1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa5aa9-44ec-4930-9d38-b91af7d6e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "def _process_ixi_xls(xls_path:(str, Path), img_path: Path):\n",
    "    '''Private method to process the demographic information for the IXI dataset.\n",
    "\n",
    "    Args:\n",
    "        xls_path: File path to the xls file with the demographic information.\n",
    "        img_path: Folder path to the images\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A processed dataframe with image path and demographic information.\n",
    "    '''\n",
    "\n",
    "    print('Preprocessing ' + str(xls_path))\n",
    "\n",
    "    df = pd.read_excel(xls_path)\n",
    "\n",
    "    duplicate_subject_ids = df[df.duplicated(['IXI_ID'], keep=False)].IXI_ID.unique()\n",
    "\n",
    "    for subject_id in duplicate_subject_ids:\n",
    "        age = df.loc[df.IXI_ID == subject_id].AGE.nunique()\n",
    "        if age != 1: df = df.loc[df.IXI_ID != subject_id] #Remove duplicates with two different age values\n",
    "\n",
    "    df = df.drop_duplicates(subset='IXI_ID', keep='first').reset_index(drop=True)\n",
    "\n",
    "    df['subject_id'] = ['IXI' + str(subject_id).zfill(3) for subject_id in df.IXI_ID.values]\n",
    "    df = df.rename(columns={'SEX_ID (1=m, 2=f)': 'gender'})\n",
    "    df['age_at_scan'] = df.AGE.round(2)\n",
    "    df = df.replace({'gender': {1:'M', 2:'F'}})\n",
    "\n",
    "    img_list = list(img_path.glob('*.nii.gz'))\n",
    "    for path in img_list:\n",
    "        subject_id = path.parts[-1].split('-')[0]\n",
    "        df.loc[df.subject_id == subject_id, 't1_path'] = path\n",
    "\n",
    "    df = df.dropna()\n",
    "    df = df[['t1_path', 'subject_id', 'gender', 'age_at_scan']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b381c8e2-6e7b-4d32-bcf7-76a1245ed893",
   "metadata": {},
   "source": [
    "## IXI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712079a2-b3b0-4658-b830-34eefe140417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def download_ixi_data(path:(str, Path)='../data' # Path to the directory where the data will be stored\n",
    "                     ):\n",
    "    '''Download T1 scans and demographic information from the IXI dataset, then process the demographic \n",
    "        information for each subject and save the information as a CSV file.\n",
    "    Returns path to the stored CSV file.\n",
    "    '''\n",
    "    path = Path(path)/'IXI'\n",
    "    img_path = path/'T1_images' \n",
    "\n",
    "    # Check whether image data already present in img_path:\n",
    "    is_extracted=False\n",
    "    try:\n",
    "        if len(list(img_path.iterdir())) >= 581: # 581 imgs in the IXI dataset\n",
    "            is_extracted=True\n",
    "            print(f\"Images already downloaded and extracted to {img_path}\")\n",
    "    except:\n",
    "        is_extracted=False\n",
    "\n",
    "    # Download and extract images\n",
    "    if not is_extracted: \n",
    "        download_and_extract(url=MURLs.IXI_DATA, filepath=path/'IXI-T1.tar', output_dir=img_path)\n",
    "        (path/'IXI-T1.tar').unlink()\n",
    "\n",
    "\n",
    "    # Download demographic info\n",
    "    download_url(url=MURLs.IXI_DEMOGRAPHIC_INFORMATION, filepath=path/'IXI.xls')\n",
    "\n",
    "    processed_df = _process_ixi_xls(xls_path=path/'IXI.xls', img_path=img_path)\n",
    "    processed_df.to_csv(path/'dataset.csv',index=False)\n",
    "\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad67127-c0c7-40e7-972d-120c09ebb527",
   "metadata": {},
   "source": [
    "## IXITiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39ec7dd-5913-41d0-823f-064fc5b9bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def download_ixi_tiny(path:(str, Path)='../data'):\n",
    "    ''' Download tiny version of IXI provided by TorchIO, containing 566 T1 brain MR scans and their corresponding brain segmentations.'''\n",
    "    \n",
    "    path = Path(path)/'IXITiny'\n",
    "    \n",
    "    #Download MR scans and segmentation masks\n",
    "    IXITiny(root=str(path), download=True)\n",
    "    # Download demographic info\n",
    "    download_url(url=MURLs.IXI_DEMOGRAPHIC_INFORMATION, filepath=path/'IXI.xls')\n",
    "    \n",
    "    processed_df = _process_ixi_xls(xls_path=path/'IXI.xls', img_path=path/'image')\n",
    "    processed_df['labels'] = processed_df['t1_path'].astype(str).str.replace('image','label')\n",
    "    \n",
    "    processed_df.to_csv(path/'dataset.csv', index=False)\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e71e62-862d-4c80-9740-2215c2ce8f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _create_spine_df(test_dir:Path):\n",
    "    # Get a list of the image files in the 'img' directory\n",
    "    img_list = glob(str(test_dir/'img/*.nii.gz'))\n",
    "\n",
    "    # Create a list of the corresponding mask files in the 'seg' directory\n",
    "    mask_list = [str(fn).replace('img', 'seg') for fn in img_list]\n",
    "\n",
    "    # Create a list of the subject IDs for each image file\n",
    "    subject_id_list = [fn.split('_')[-1].split('.')[0] for fn in mask_list]\n",
    "    \n",
    "    # Create a dictionary containing the test data\n",
    "    test_data = {'t2_img_path':img_list, 't2_mask_path':mask_list, 'subject_id':subject_id_list, 'is_test':True}\n",
    "\n",
    "    # Create a DataFrame from the example data dictionary\n",
    "    return pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17de9ba6-00b5-408e-8dee-abafc62926ef",
   "metadata": {},
   "source": [
    "## Lower spine data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336f687b-7997-43ab-a2a0-32376c329fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export    \n",
    "def download_spine_test_data(path:(str, Path)='../data'):\n",
    "    \n",
    "    ''' Download T2w scans from 'Fully Automatic Localization and Segmentation of 3D Vertebral Bodies from CT/MR Images via a Learning-Based Method' study by Chu et. al. \n",
    "    Returns a processed dataframe with image path, label path and subject IDs. \n",
    "    '''\n",
    "    study = 'chengwen_chu_2015'\n",
    "    \n",
    "    download_and_extract(url=MURLs.CHENGWEN_CHU_SPINE_DATA, filepath=f'{study}.zip', output_dir=path)\n",
    "    Path(f'{study}.zip').unlink()\n",
    "    \n",
    "    return _create_spine_df(Path(path)/study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0fae60-db03-4ead-a9e4-0e092d62d3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def download_example_spine_data(path:(str, Path)='../data'): \n",
    "    \n",
    "    '''Download example T2w scan and predicted mask.'''\n",
    "    study = 'example_data'\n",
    "    \n",
    "    download_and_extract(url=MURLs.EXAMPLE_SPINE_DATA, filepath='example_data.zip', output_dir=path);\n",
    "    Path('example_data.zip').unlink()\n",
    "    \n",
    "    return Path(path/study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228c0417-392c-4897-949c-d2cb572cd855",
   "metadata": {},
   "source": [
    "## NoduleMNIST3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b05b40-aeee-4906-aa98-ff79b3d667fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def _process_nodule_img(path, idx_arr):\n",
    "    '''Save tensor as NIfTI.'''\n",
    "    idx, arr = idx_arr\n",
    "    img = ScalarImage(tensor=arr[None, :])\n",
    "    fn = path/f'{idx}_nodule.nii.gz'\n",
    "    img.save(fn)\n",
    "    return str(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc07388c-50e9-4cb4-ab0e-62ae88d8c0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def _df_sort_and_add_columns(df, label_list, is_val):\n",
    "    '''Sort the dataframe based on img_idx and add labels and if it is validation data column'''\n",
    "    df = df.sort_values(by='img_idx').reset_index(drop=True)\n",
    "    df['labels'], df['is_val'] = label_list, is_val     \n",
    "    df = df.drop('img_idx', axis=1)\n",
    "    \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dd1afb-6028-4daa-aa05-41d57c7d9355",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def _create_nodule_df(pool, output_dir, imgs, labels, is_val=False): \n",
    "    '''Create dataframe for NoduleMNIST3D data.'''\n",
    "    img_path_list = pool.map(partial(_process_nodule_img, output_dir), enumerate(imgs))\n",
    "    img_idx = [float(Path(fn).parts[-1].split('_')[0]) for fn in img_path_list]\n",
    "    \n",
    "    df = pd.DataFrame(list(zip(img_path_list, img_idx)), columns=['img_path','img_idx'])        \n",
    "    return  _df_sort_and_add_columns(df, labels, is_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97237f95-ed5b-4134-88df-a61d5b48d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def download_NoduleMNIST3D(path:(str, Path)='../data', max_workers=1): \n",
    "    \n",
    "    '''Download ....'''\n",
    "    study = 'NoduleMNIST3D'\n",
    "    path = Path(path)/study\n",
    "    \n",
    "    download_url(url=MURLs.NODULE_MNIST_DATA, filepath=path/f'{study}.npz');\n",
    "    data = load(path/f'{study}.npz')\n",
    "    key_fn = ['train_images', 'val_images', 'test_images']    \n",
    "    for fn in key_fn: (path/fn).mkdir(exist_ok=True)\n",
    "    \n",
    "    \n",
    "    train_imgs, val_imgs, test_imgs = data[key_fn[0]], data[key_fn[1]], data[key_fn[2]]\n",
    "\n",
    "\n",
    "    with mp.Pool(processes=max_workers) as p:\n",
    "        \n",
    "        train_df = _create_nodule_df(p, path/key_fn[0], train_imgs, data['train_labels'])\n",
    "        val_df = _create_nodule_df(p, path/key_fn[1], val_imgs, data['val_labels'], is_val=True)\n",
    "        test_df = _create_nodule_df(p, path/key_fn[2], test_imgs, data['test_labels'])\n",
    "    \n",
    "    train_val_df = pd.concat([train_df, val_df], ignore_index=True)\n",
    "    \n",
    "    return train_val_df, test_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
