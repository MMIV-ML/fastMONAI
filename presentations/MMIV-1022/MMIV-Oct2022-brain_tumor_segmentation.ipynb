{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4952034",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Brain-tumor-segmentation-using-fastMONAI\" data-toc-modified-id=\"Brain-tumor-segmentation-using-fastMONAI-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Brain tumor segmentation using <code>fastMONAI</code></a></span></li><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Setup</a></span></li><li><span><a href=\"#Load-and-inspect-the-data\" data-toc-modified-id=\"Load-and-inspect-the-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Load and inspect the data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Inspect-the-data\" data-toc-modified-id=\"Inspect-the-data-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Inspect the data</a></span></li><li><span><a href=\"#Data-augmentation-and-dataloaders\" data-toc-modified-id=\"Data-augmentation-and-dataloaders-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Data augmentation and dataloaders</a></span><ul class=\"toc-item\"><li><span><a href=\"#What-is-data-augmentation?\" data-toc-modified-id=\"What-is-data-augmentation?-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>What is data augmentation?</a></span></li><li><span><a href=\"#Create-dataloaders\" data-toc-modified-id=\"Create-dataloaders-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Create dataloaders</a></span></li></ul></li></ul></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-architecture\" data-toc-modified-id=\"Model-architecture-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Model architecture</a></span></li><li><span><a href=\"#Loss-function\" data-toc-modified-id=\"Loss-function-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Loss function</a></span></li></ul></li><li><span><a href=\"#Evaluate-results\" data-toc-modified-id=\"Evaluate-results-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Evaluate results</a></span><ul class=\"toc-item\"><li><span><a href=\"#Inference-on-test-data\" data-toc-modified-id=\"Inference-on-test-data-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Inference on test data</a></span></li></ul></li><li><span><a href=\"#Export-the-model-and-dataloader\" data-toc-modified-id=\"Export-the-model-and-dataloader-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Export the model and dataloader</a></span></li><li><span><a href=\"#Extra:-Radiomics\" data-toc-modified-id=\"Extra:-Radiomics-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Extra: Radiomics</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5383757c",
   "metadata": {},
   "source": [
    "# Brain tumor segmentation using `fastMONAI`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fbb1bf",
   "metadata": {},
   "source": [
    "This notebook illustrates an approach to constructing a brain tumor segmentation model based on MR images. We aim to extract meaningful tumor regions directly from multimodal MRI (T1w, T1ce, T2w, and FLAIR). In this case, the active tumor (AT), necrotic core (NCR), and peritumoral edematous/infiltrated tissue (ED)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe26dbc",
   "metadata": {},
   "source": [
    "<img width=40% src=\"https://github.com/MMIV-ML/fastMONAI/raw/master/presentations/MMIV-1022/assets/brain_tumor.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16210b9-de33-4afa-90d3-733c909924f2",
   "metadata": {},
   "source": [
    "[![Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MMIV-ML/fastMONAI/blob/master/presentations/MMIV-1022/MMIV-Oct2022-brain_tumor_segmentation.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b65d51",
   "metadata": {},
   "source": [
    "Here's an illustration of what we want to achieve (illustration taken from the BraTS Challenge):\n",
    "\n",
    "<img src=\"https://www.med.upenn.edu/cbica/assets/user-content/images/BraTS/brats-tumor-subregions.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090b4c80",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c7f192",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We must first set up the software libraries we'll use to construct our model. Chief among these is the `fastMONAI` library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf73ca66",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<a href=\"https://fastmonai.no\"><img src=\"https://github.com/MMIV-ML/fastMONAI/raw/master/presentations/MMIV-1022/assets/fastmonai_no.png\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff229bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# This is a quick check of whether the notebook is currently \n",
    "# running on Google Colaboratory or on Kaggle, \n",
    "# as that makes some difference for the code below.\n",
    "\n",
    "try:\n",
    "    import colab\n",
    "    colab=True\n",
    "except:\n",
    "    colab=False\n",
    "\n",
    "import os\n",
    "kaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
    "\n",
    "#Install `fastMONAI` if notebook is running on Google Colab or on Kaggle\n",
    "if (colab or kaggle):\n",
    "    %pip install fastMONAI\n",
    "    if colab:\n",
    "        from fastMONAI.utils import print_colab_gpu_info\n",
    "        print_colab_gpu_info()\n",
    "else:\n",
    "    print('Running locally')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6176b786-ed78-420d-b139-05f2819a2c7a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from fastMONAI.vision_all import *\n",
    "\n",
    "from monai.apps import DecathlonDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee80137-1f65-4ffd-99a9-8365824b18b7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load and inspect the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0e83b1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> We will use the brain tumors dataset from the Medical Segmentation Decathlon challenge (http://medicaldecathlon.com/). The data is collected from the Multimodal Brain Tumor Image Segmentation Benchmark Challenge (BraTS) dataset from 2016 and 2017. The task is to segment tumors into three different subregions (active tumor (AT), necrotic core (NCR), and peritumoral edematous/infiltrated tissue (ED)) from multimodal multisite MRI data (T1w, T1ce, T2w, and FLAIR). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc45d62a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"https://github.com/MMIV-ML/fastMONAI/raw/master/presentations/MMIV-1022/assets/brats-montage.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da1ac05-db4f-428f-b864-5af25d7b5a00",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We use the MONAI function `DecathlonDataset` to download the data and generate items for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798a15cc-c60f-40e1-98c5-3adc662062c3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = Path('data')\n",
    "path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48e6df0-77cc-46df-8be1-0a6edb074057",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "training_data = DecathlonDataset(root_dir=path, task=\"Task01_BrainTumour\", section=\"training\", download=True,\n",
    "                                 cache_num=0, num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4b73f5-eaa9-4609-8bd7-e1d0ac017cb2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(training_data.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff699329",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We now have a bunch of images and corresponding labels. Here are the first five:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44295395",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8904644",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c508542",
   "metadata": {},
   "source": [
    "Each of the 388 data sets consists of four 3D volumes (T1, T1c, T2, FLAIR) and corresponding manual labels. Here's one example:<br><br>\n",
    "\n",
    "<img src=\"https://github.com/MMIV-ML/fastMONAI/raw/master/presentations/MMIV-1022/assets/img_182_axial.gif\"><img src=\"https://github.com/MMIV-ML/fastMONAI/raw/master/presentations/MMIV-1022/assets/img_182_coronal.gif\"><img src=\"https://github.com/MMIV-ML/fastMONAI/raw/master/presentations/MMIV-1022/assets/img_182_sagittal.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cee363e-6852-4e1e-90af-79ee1c49bcd8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will train our model on parts of the data set, the so-called **training data**. After training, we'll need some new data to test our model's ability to generalize to unseen data, so-called **test data**. \n",
    "\n",
    "This is achieved by splitting the labeled data into two sets: training and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe202ae-8c6e-4bd6-991f-3ce424c51078",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd77b358-9b7d-48d1-9d7b-fe181216c7fb",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Inspect the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0694b5a5",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`fastMONAI` has a useful function to construct a dataset from a list of labeled images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eea80f8-4e28-4b6d-8471-cbfd0e5621b6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "med_dataset = MedDataset(img_list=train_df.label.tolist()[:20], dtype=MedMask, max_workers=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc3acaf",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It provides useful information about our data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be336f60-29d5-480d-aa07-58539673a5f6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "med_dataset.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce236981-c784-4397-ab66-e220cb2bd7a2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "summary_df = med_dataset.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35327eb-e51a-42c9-b70e-a824c30ef4de",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e273c20b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We observe that in this case the voxel spacing is the same for all 349 images, and also that they are oriented identically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410c5cdf-839b-47bb-85cb-0908379f65d6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "resample, reorder = med_dataset.suggestion()\n",
    "resample, reorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19001bbf-0db5-4de4-b87a-c5214cc9930a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "img_size = med_dataset.get_largest_img_size(resample=resample)\n",
    "img_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae302a15",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Data augmentation and dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a1027a",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### What is data augmentation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7917a9e4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "By doing **data augmentation**, one aims to increase the diversity of a given data set by performing random, realistic transformations of the data. For images, these transformations can be rotations, flips, zooming, pixel intensity modifications, and much more. This also ensures a degree of **invariance** to these transformations for the resulting trained models.\n",
    "\n",
    "There are many possible data augmentation techniques, ranging from basic to more advanced transformations, including methods for combining multiple images into sets of \"new\" images (e.g., what's called \"CutMix\" or \"MixUp\" and more).\n",
    "\n",
    "Here are some illustrations of various data augmentation strategies (taken from https://www.quantib.com/blog/image-augmentation-how-to-overcome-small-radiology-datasets): "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7075515",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"https://www.quantib.com/hs-fs/hubfs/Blog%20and%20news%20images/Examples%20of%20rigid%20augmentation%20-%20AI%20in%20radiology%20-%20Quantib.png?width=1549&name=Examples%20of%20rigid%20augmentation%20-%20AI%20in%20radiology%20-%20Quantib.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01381a14",
   "metadata": {},
   "source": [
    "<img src=\"https://www.quantib.com/hs-fs/hubfs/assets/images/blog/Examples%20of%20stretch%20augmentation%20-%20AI%20in%20radiology%20-%20Quantib.png?width=3098&name=Examples%20of%20stretch%20augmentation%20-%20AI%20in%20radiology%20-%20Quantib.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01381a14",
   "metadata": {},
   "source": [
    "<img src=\"https://www.quantib.com/hs-fs/hubfs/Blog%20and%20news%20images/Examples%20of%20elastic%20augmentation%20-%20AI%20in%20radiology%20-%20Quantib.png?width=1448&name=Examples%20of%20elastic%20augmentation%20-%20AI%20in%20radiology%20-%20Quantib.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ee1399",
   "metadata": {},
   "source": [
    "<img src=\"https://www.quantib.com/hs-fs/hubfs/Blog%20and%20news%20images/Contrast%20shift%20augmentation%20-%20AI%20in%20radiology%20-%20Quantib-1.png?width=1072&name=Contrast%20shift%20augmentation%20-%20AI%20in%20radiology%20-%20Quantib-1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c52f22c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "When doing data augmentation, it is vital that\n",
    "\n",
    "(i) the transformations won't change the correct label (f.ex., zooming in on a region of the image that doesn't contain the information needed to assign the class of the original image. Think zooming in on a part of a bone X-ray that doesn't include the finding of interest, say, a fracture)<br><br>\n",
    "(ii) be at least somewhat realistic (f.ex., if you expect all the images to have a fixed up-down orientation, as is typically the case in, say, head MRI, vertical flips will not be a good idea).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d73952",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In our case, we normalize the image, resize them all to the same size, and do some random motion as our data augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ddb60-3d8b-4b13-bd44-69dfaff2661d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "size=[224,224,128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fc0c9d-e38f-4c67-b3a0-cbf20b35427b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "item_tfms = [ZNormalization(), PadOrCrop(size), RandomAffine(scales=0, degrees=5, isotropic=True)] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c81779",
   "metadata": {
    "hidden": true
   },
   "source": [
    "After creating dataloaders that apply these transformations, we can have a look at the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34a3435",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb95969",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dblock = MedDataBlock(blocks=(ImageBlock(cls=MedImage), MedMaskBlock), \n",
    "                      splitter=RandomSplitter(seed=42),\n",
    "                      get_x=ColReader('image'),\n",
    "                      get_y=ColReader('label'),\n",
    "                      item_tfms=item_tfms,\n",
    "                      batch_tfms=None,\n",
    "                      reorder=reorder,\n",
    "                      resample=resample) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17a1c6c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bs=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f52d85",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(train_df, bs=bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aaaf4c",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here's the effect of our data augmentation applied to a single image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c8df7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dls.show_batch(anatomical_plane=0, unique=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423d8338-4c6a-482f-91d1-ac401bdcfd4a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# training and validation\n",
    "len(dls.train_ds.items), len(dls.valid_ds.items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f809d893",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here's a batch of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b50e265-4cc9-4896-9542-0b6fa3333c25",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dls.show_batch(anatomical_plane=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2754ef09-7729-43e1-be84-0be49aa757dc",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a49526",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87ab184",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We use an enhanced version of UNet from MONAI. \n",
    "\n",
    "Here's an illustration of the basic UNet architecture on which our model is built:\n",
    "\n",
    "<img src=\"https://github.com/MMIV-ML/fastMONAI/raw/master/presentations/MMIV-1022/assets/unet.jpeg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f2558",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from monai.networks.nets import UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462b70e1",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e7ada2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The Dice coeffiecient measures the degree of overlap between the predicted tumor mask and the \"ground truth\" masks:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44354e7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img width=20% src=\"https://github.com/MMIV-ML/fastMONAI/raw/master/presentations/MMIV-1022/assets/dice.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea40322",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We use a loss function that combines Dice loss and Cross Entropy loss and returns the weighted sum of these two losses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501d1c94-9104-4ce5-a625-63bb93a8216e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from monai.losses import DiceCELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4998f122-0658-4df8-91c7-19229a032bd4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "codes = np.unique(med_img_reader(train_df.label.tolist()[0]))\n",
    "n_classes = len(codes)\n",
    "codes, n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade79530-28f1-4cdc-a037-c0db5511d4a3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = UNet(dimensions=3, in_channels=4, out_channels=n_classes, \n",
    "             channels=(16, 32, 64, 128, 256),strides=(2, 2, 2, 2), \n",
    "             num_res_units=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acca18cc-d019-464d-87c9-c7b770c1a913",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss_func = CustomLoss(loss_func=DiceCELoss(to_onehot_y=True, include_background=True, softmax=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55507a79",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c29e24f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we're ready to train the model. After training, we'll have something that can produce the following results on new, unseen MR recordings:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b390b345",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img width=60% src=\"https://github.com/MMIV-ML/fastMONAI/raw/master/presentations/MMIV-1022/assets/prediction_results.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e411713e",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/MMIV-ML/fastMONAI/raw/master/presentations/MMIV-1022/assets/pred_093.gif\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c771ce6-1607-4cd8-9dfc-55cd87898107",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, loss_func=loss_func, opt_func=ranger, metrics=multi_dice_score)#.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4e4674-f2a0-47cc-a2ae-9791eada964d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if not (colab or kaggle):\n",
    "    lr = learn.lr_find()\n",
    "else:\n",
    "    lr = 8e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d898a6f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In the interest of time, our model is trained for only a few epochs. If you have the time, you can raise this number to something higher (f.ex. `epochs=30` or more) to get a model that performs much better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ef98d2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976e37ca-3cda-4f6d-90df-6dade086a670",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.fit_flat_cos(epochs, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ba9f2a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if (colab or kaggle):\n",
    "    !wget https://www.dropbox.com/s/tmebx1m4q57tn7b/trained.braintumor-model.pth?dl=1\n",
    "    !mkdir models\n",
    "    !mv trained.braintumor-model.pth?dl=1 models/trained.braintumor-model.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ed114e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('trained.braintumor-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cd48c2-8a62-47b2-a0f9-0e6bd064ef8a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#learn.save('trained.braintumor-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006e3e01",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Evaluate results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b586eb5d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's check how the model performs on some validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee274a7-8bad-4b3d-84a5-ede9dd35ea21",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.show_results(anatomical_plane=0, ds_idx=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abaa657-54bf-4774-90a1-b2b8996585b6",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Inference on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194790df",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Remember that we also have some unseen test data that we can try our model on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7851b941-d2ee-4d60-9c57-0c82e85273b2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_dl = learn.dls.test_dl(test_df[:10],with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06f24c9-bb9b-49f9-b5e4-7ad722bac89b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_dl.show_batch(anatomical_plane=0, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cd2d80-cd0b-480c-b243-da9fa0e06369",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred_acts, labels = learn.get_preds(dl=test_dl)\n",
    "pred_acts.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65bfb77-f7f7-4bc3-9fe1-24df0ae087f2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Dice score for labels 1,2 and 3: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21359ed4-2cbf-4767-8186-59447335f8a1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_dice_score(pred_acts, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70c2c67-1af2-42bb-99d8-54438aa303bf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.show_results(anatomical_plane=0, dl=test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8df2f0-f6d7-42dd-a528-a8d19df9d8e4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Export the model and dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d1d83b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The final step is to export the model and the pre-processing steps so that they can be used in some further context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b64d99e-6587-451f-b5bc-fb0df752a529",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "store_variables(pkl_fn='vars.pkl', var_vals=[reorder, resample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfeb8b2-fef2-4833-9695-3aa93a216008",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.export('braintumor_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43bf890",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This model can then, in principle, be taken further into an infrastructure where it can be tested against new data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3904eb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For example, one can use the \"research PACS\" infrastructure to host and run such models. You've now constructed the \"Segmentation application\" in the illustration below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56fd4c1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img width=\"60%\" src=\"https://github.com/MMIV-ML/fastMONAI/raw/master/presentations/MMIV-1022/assets/deploy.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8662750b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Extra material: Radiomics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c924ad02",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Once we've segmented tumors into meaningful subcompartments, we have a set of regions of interest (ROIs) and can start asking many interesting questions. Computing the tumor volumes is an obvious idea. We can also try to compute various shape characteristics. Perhaps the intensity variation in the tumor is a valuable indicator of tumor hetereogeneity. What about the tumor location? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1e4479",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Extracting features from objects of interest in medical images for diagnostic purposes is often referred to as **radiomics**. The goal of radiomics is to extract information from medical images that can be used as part of a medical imaging-based diagnostic workflow. The information can be extracted from various imaging modalities, e.g., different MRI contrasts, PET imaging, CT imaging, etc. One can then combine it with other sources of information (e.g., demographics, clinical data, genetics). In such a way, radiomics–and radiogenomics–can open the door to sophisticated and powerful analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89fa012",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Radiomics workflow:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a76e35",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"https://github.com/MMIV-ML/fastMONAI/raw/master/presentations/MMIV-1022/assets/radiomics.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d674db8f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If you're interested, you can have a look at a basic radiomics approach here: https://github.com/MMIV-ML/presimal2022."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('fastmonai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "4ca7f31efac125d444ca4121b3c25be092005658b657791dbeb0737ec054bcd2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
